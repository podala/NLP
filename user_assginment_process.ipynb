{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the dataset\n",
    "data = pd.read_csv(\"user_assignments.csv\")\n",
    "\n",
    "# define the features and target variable\n",
    "features = [\"user_status\", \"user_availability\", \"user_task_count\", \"user_threshold\", \n",
    "            \"user_experience_level\", \"user_location\", \"user_feedback\", \"task_urgency\", \"task_complexity\"]\n",
    "target = \"assigned\"\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2)\n",
    "\n",
    "# create the logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the assign_user function\n",
    "def assign_user(member_location, task_urgency, task_complexity):\n",
    "    # filter the data to include only users who are available and meet the threshold\n",
    "    filtered_data = data[(data[\"user_availability\"] == \"available\") & \n",
    "                         (data[\"user_threshold\"] > data[\"user_task_count\"]) &\n",
    "                         (data[\"member_location\"] == user_location)]\n",
    "\n",
    "    # if there are no suitable users, return None\n",
    "    if len(filtered_data) == 0:\n",
    "        return None,data\n",
    "\n",
    "    # select a user randomly from the filtered data\n",
    "    selected_user = random.choice(filtered_data.index)\n",
    "\n",
    "    # assign the task to the selected user\n",
    "    data.loc[selected_user, \"user_task_count\"] += 1\n",
    "    data.loc[selected_user, \"assigned\"] = True\n",
    "    data.loc[selected_user, \"task_urgency\"] = task_urgency\n",
    "    data.loc[selected_user, \"task_complexity\"] = task_complexity\n",
    "\n",
    "    # return the selected user\n",
    "    return selected_user,data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(\"assigned\", axis=1), \n",
    "                                                    data[\"assigned\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load the dataset\n",
    "data = pd.read_csv(\"user_assignments.csv\")\n",
    "\n",
    "# preprocess the data\n",
    "features = [\"user_status\", \"user_availability\", \"user_task_count\", \"user_threshold\",\n",
    "            \"user_experience_level\", \"user_feedback\", \"task_urgency\", \"task_complexity\",\n",
    "            \"member_location\"]\n",
    "data = pd.get_dummies(data, columns=[col for col in features if col != \"user_task_count\"])\n",
    "data[\"assigned\"] = data[\"assigned\"].astype(int)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(\"assigned\", axis=1), \n",
    "                                                    data[\"assigned\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# build the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "def assign_user(user_status, user_availability, user_task_count, user_threshold,\n",
    "                user_experience_level, user_feedback, task_urgency, task_complexity, \n",
    "                member_location):\n",
    "    # create a dataframe with the input features\n",
    "    input_data = pd.DataFrame({\n",
    "        \"user_status_\" + user_status: [1],\n",
    "        \"user_availability_\" + user_availability: [1],\n",
    "        \"user_task_count\": [user_task_count],\n",
    "        \"user_threshold\": [user_threshold],\n",
    "        \"user_experience_level_\" + user_experience_level: [1],\n",
    "        \"user_feedback\": [user_feedback],\n",
    "        \"task_urgency_\" + task_urgency: [1],\n",
    "        \"task_complexity_\" + task_complexity: [1],\n",
    "        \"member_location_\" + member_location: [1]\n",
    "    })\n",
    "\n",
    "    # use the model to make a prediction\n",
    "    prediction = model.predict(input_data)\n",
    "\n",
    "    # if the prediction is 0, return None\n",
    "    if prediction == 0:\n",
    "        return None, data\n",
    "\n",
    "    # select a user randomly from the filtered data\n",
    "    filtered_data = data[(data[\"user_status\"] == user_status) & \n",
    "                         (data[\"user_availability\"] == user_availability) & \n",
    "                         (data[\"user_task_count\"] < user_threshold) &\n",
    "                         (data[\"user_experience_level\"] == user_experience_level) &\n",
    "                         (data[\"user_feedback\"] >= user_feedback) &\n",
    "                         (data[\"task_urgency_\" + task_urgency] == 1) &\n",
    "                         (data[\"task_complexity_\" + task_complexity] == 1) &\n",
    "                         (data[\"member_location_\" + member_location] == 1)]\n",
    "    \n",
    "    if len(filtered_data) == 0:\n",
    "        return None, data\n",
    "\n",
    "    selected_user = filtered_data.sample()\n",
    "    selected_user_id = selected_user.index[0]\n",
    "    data.at[selected_user_id, \"user_task_count\"] += 1\n",
    "    return selected_user, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load the dataset\n",
    "data = pd.read_csv(\"user_assignments.csv\")\n",
    "\n",
    "# preprocess the data\n",
    "features = [\"user_status\", \"user_availability\", \"user_task_count\", \"user_threshold\",\n",
    "            \"user_experience_level\", \"user_feedback\", \"task_urgency\", \"task_complexity\",\n",
    "            \"member_location\"]\n",
    "data = pd.get_dummies(data, columns=[col for col in features if col != \"user_task_count\"])\n",
    "data[\"assigned\"] = data[\"assigned\"].astype(int)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(\"assigned\", axis=1), \n",
    "                                                    data[\"assigned\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# build the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "def assign_user(user_status, user_availability, user_task_count, user_threshold,\n",
    "                user_experience_level, user_feedback, task_urgency, task_complexity, \n",
    "                member_location, team_size):\n",
    "    # create a dataframe with the input features\n",
    "    input_data = pd.DataFrame({\n",
    "        \"user_status_\" + user_status: [1],\n",
    "        \"user_availability_\" + user_availability: [1],\n",
    "        \"user_task_count\": [user_task_count],\n",
    "        \"user_threshold\": [user_threshold],\n",
    "        \"user_experience_level_\" + user_experience_level: [1],\n",
    "        \"user_feedback\": [user_feedback],\n",
    "        \"task_urgency_\" + task_urgency: [1],\n",
    "        \"task_complexity_\" + task_complexity: [1],\n",
    "        \"member_location_\" + member_location: [1]\n",
    "    })\n",
    "\n",
    "    # use the model to make a prediction\n",
    "    prediction = model.predict(input_data)\n",
    "\n",
    "    # if the prediction is 0, return None\n",
    "    if prediction == 0:\n",
    "        return None, data\n",
    "\n",
    "    # select a team of users randomly from the filtered data\n",
    "    filtered_data = data[(data[\"user_status\"] == user_status) & \n",
    "                         (data[\"user_availability\"] == user_availability) & \n",
    "                         (data[\"user_task_count\"] < user_threshold) &\n",
    "                         (data[\"user_experience_level\"] == user_experience_level) &\n",
    "                         (data[\"user_feedback\"] >= user_feedback) &\n",
    "                         (data[\"task_urgency_\" + task_urgency] == 1) &\n",
    "                         (data[\"task_complexity_\" + task_complexity] == 1) &\n",
    "                         (data[\"member_location_\" + member_location] == 1)]\n",
    "    \n",
    "    if len(filtered_data) == 0:\n",
    "        return None, data\n",
    "\n",
    "    selected_users = filtered_data.sample(n=team_size)\n",
    "    selected_user_ids = selected_users.index\n",
    "    data.loc[selected_user_ids, \"user_task_count\"] += 1\n",
    "    return selected_users, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "# load the dataset\n",
    "data = pd.read_csv(\"user_assignments.csv\")\n",
    "\n",
    "# preprocess the data\n",
    "features = [\"user_status\", \"user_availability\", \"user_task_count\", \"user_threshold\",\n",
    "            \"user_experience_level\", \"user_feedback\", \"task_urgency\", \"task_complexity\",\n",
    "            \"member_location\"]\n",
    "data = pd.get_dummies(data, columns=[col for col in features if col != \"user_task_count\"])\n",
    "data[\"assigned\"] = data[\"assigned\"].astype(int)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(\"assigned\", axis=1), \n",
    "                                                    data[\"assigned\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# perform feature importance analysis\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "importances = model.feature_importances_\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "for idx in sorted_idx:\n",
    "    print(f\"{X_train.columns[idx]}: {importances[idx]}\")\n",
    "\n",
    "# hyperparameter tuning using cross-validation\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"]\n",
    "}\n",
    "cv = GridSearchCV(RandomForestClassifier(random_state=42), \n",
    "                  param_grid=param_grid, \n",
    "                  cv=5, \n",
    "                  n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "print(f\"Best hyperparameters: {cv.best_params_}\")\n",
    "print(f\"Cross-validation score: {cv.best_score_}\")\n",
    "\n",
    "# build the model with the best hyperparameters\n",
    "model = RandomForestClassifier(n_estimators=cv.best_params_[\"n_estimators\"],\n",
    "                               max_depth=cv.best_params_[\"max_depth\"],\n",
    "                               min_samples_split=cv.best_params_[\"min_samples_split\"],\n",
    "                               min_samples_leaf=cv.best_params_[\"min_samples_leaf\"],\n",
    "                               max_features=cv.best_params_[\"max_features\"],\n",
    "                               random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "def assign_user(user_status, user_availability, user_task_count, user_threshold,\n",
    "                user_experience_level, user_feedback, task_urgency, task_complexity, \n",
    "                member_location, team_size):\n",
    "    # create a dataframe with the input features\n",
    "    input_data = pd.DataFrame({\n",
    "        \"user_status_\" + user_status: [1],\n",
    "        \"user_availability_\" + user_availability: [1],\n",
    "        \"user_task_count\": [user_task_count],\n",
    "        \"user_threshold\": [user_threshold],\n",
    "        \"user_experience_level_\" + user_experience_level: [1],\n",
    "        \"user_feedback\": [user_feedback],\n",
    "        \"task_urgency_\" + task_urgency: [1],\n",
    "        \"task_complexity_\" + task_complexity: [1],\n",
    "        \"member_location_\" + member_location: [1]\n",
    "    })\n",
    "\n",
    "    # use the model to make a prediction\n",
    "    prediction = model.predict(input_data)\n",
    "\n",
    "    # if the prediction is 0, return None\n",
    "    if prediction == 0:\n",
    "        return None, data\n",
    "\n",
    "    # select a team of users randomly from the filtered data\n",
    "    filtered_data = data[(data[\"user_status\"] == user_status) & \n",
    "                         (data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
